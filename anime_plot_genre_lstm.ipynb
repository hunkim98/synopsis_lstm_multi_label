{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# https://github.com/WillKoehrsen/recurrent-neural-networks/blob/master/notebooks/Deep%20Dive%20into%20Recurrent%20Neural%20Networks.ipynb\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "RANDOM_STATE = 50\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "TRAINING_LENGTH = 20\n",
    "TRAIN_FRACTION = 0.7\n",
    "LSTM_CELLS = 16\n",
    "VERBOSE = 1\n",
    "MIN_WORD_COUNT = 10\n",
    "SAVE_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data = pd.read_csv(\"./data/anime_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anime_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Type</th>\n",
       "      <th>Producer</th>\n",
       "      <th>Studio</th>\n",
       "      <th>Rating</th>\n",
       "      <th>ScoredBy</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Members</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Source</th>\n",
       "      <th>Aired</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>['Action', 'Adventure', 'Comedy', 'Drama', 'Sc...</td>\n",
       "      <td>In the year 2071, humanity has colonized sever...</td>\n",
       "      <td>TV</td>\n",
       "      <td>['Bandai Visual']</td>\n",
       "      <td>['Sunrise']</td>\n",
       "      <td>8.81</td>\n",
       "      <td>363889.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>704490.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Original</td>\n",
       "      <td>Apr 3, 1998 to Apr 24, 1999</td>\n",
       "      <td>https://myanimelist.net/anime/1/Cowboy_Bebop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Anime_id         Title                                              Genre  \\\n",
       "0         1  Cowboy Bebop  ['Action', 'Adventure', 'Comedy', 'Drama', 'Sc...   \n",
       "\n",
       "                                            Synopsis Type           Producer  \\\n",
       "0  In the year 2071, humanity has colonized sever...   TV  ['Bandai Visual']   \n",
       "\n",
       "        Studio  Rating  ScoredBy  Popularity   Members  Episodes    Source  \\\n",
       "0  ['Sunrise']    8.81  363889.0        39.0  704490.0      26.0  Original   \n",
       "\n",
       "                         Aired                                          Link  \n",
       "0  Apr 3, 1998 to Apr 24, 1999  https://myanimelist.net/anime/1/Cowboy_Bebop  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_synopsis_column_name = \"Synopsis\"\n",
    "anime_genre_column_name = \"Genre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def is_over_min_word_count(text):\n",
    "    return word_count(text) >= MIN_WORD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "anime_data.drop(anime_data[anime_data[anime_synopsis_column_name].isnull()].index, inplace=True)\n",
    "anime_data.drop(anime_data[anime_data[anime_genre_column_name].isnull()].index, inplace=True)\n",
    "anime_data.drop(anime_data[anime_data[anime_synopsis_column_name].apply(word_count) == 0].index, inplace=True)\n",
    "anime_data.drop(anime_data[anime_data[anime_synopsis_column_name].apply(is_over_min_word_count) == False].index, inplace=True)\n",
    "anime_data[anime_synopsis_column_name].isnull().sum()\n",
    "anime_data[anime_genre_column_name].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_synopsis = list(anime_data[anime_synopsis_column_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Stop words are words like \"a\", \"the\", or \"in\" which don't convey significant meaning.\n",
    "# They're usually removed from text before processing.\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "    \n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_phrase(sentance):\n",
    "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
    "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
    "    sentance = decontracted(sentance)\n",
    "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
    "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
    "    sentance = re.sub('[^A-Za-z0-9]+', ' ', sentance)\n",
    "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stopwords)\n",
    "    return sentance.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'year humanity colonized several planets moons solar system leaving uninhabitable surface planet earth behind inter solar system police attempts keep peace galaxy aided part outlaw bounty hunters referred cowboys ragtag team aboard spaceship bebop two individuals mellow carefree spike spiegel balanced boisterous pragmatic partner jet black pair makes living chasing bounties collecting rewards thrown course addition new members meet travels ein genetically engineered highly intelligent welsh corgi femme fatale faye valentine enigmatic trickster memory loss strange computer whiz kid edward wong crew embarks thrilling adventures unravel member dark mysterious past little little well balanced high density action light hearted comedy cowboy bebop space western classic homage smooth improvised music named written mal rewrite'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_phrase(anime_data[anime_synopsis_column_name][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function “decontracted” defined above takes a text column from a data frame and removes all HTML tags and special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year humanity colonized several planets moons solar system leaving uninhabitable surface planet earth behind inter solar system police attempts keep peace galaxy aided part outlaw bounty hunters referred cowboys ragtag team aboard spaceship bebop two individuals mellow carefree spike spiegel balanced boisterous pragmatic partner jet black pair makes living chasing bounties collecting rewards thrown course addition new members meet travels ein genetically engineered highly intelligent welsh corgi femme fatale faye valentine enigmatic trickster memory loss strange computer whiz kid edward wong crew embarks thrilling adventures unravel member dark mysterious past little little well balanced high density action light hearted comedy cowboy bebop space western classic homage smooth improvised music named written mal rewrite\n"
     ]
    }
   ],
   "source": [
    "preprocessed_synopsis = []\n",
    "# we use stop words only for tasks like classification where we don't need the exact words\n",
    "# but for text generation we need the exact words so we don't use stop words\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in anime_data[anime_synopsis_column_name].values:\n",
    "    processed_sentence = preprocess_phrase(sentance)\n",
    "    preprocessed_synopsis.append(processed_sentence)\n",
    "\n",
    "print(preprocessed_synopsis[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(x):\n",
    "    x=x.split(\",\")\n",
    "    nospace=[]\n",
    "    for item in x:\n",
    "        item=item.lstrip()\n",
    "        nospace.append(item)\n",
    "    return (\",\").join(nospace)\n",
    "\n",
    "def remove_out_brackets(x):\n",
    "    x=x.split(\",\")\n",
    "    nospace=[]\n",
    "    for item in x:\n",
    "        item=item.replace(\"[\",\"\")\n",
    "        item=item.replace(\"]\",\"\")\n",
    "        nospace.append(item)\n",
    "    return (\",\").join(nospace)\n",
    "\n",
    "def remove_quote_mark(x):\n",
    "    x=x.split(\",\")\n",
    "    nospace=[]\n",
    "    for item in x:\n",
    "        item=item.replace(\"'\",\"\")\n",
    "        nospace.append(item)\n",
    "    return (\",\").join(nospace)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_data[anime_genre_column_name].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_data[anime_genre_column_name]=anime_data[anime_genre_column_name].apply(remove_spaces)\n",
    "anime_data[anime_genre_column_name]=anime_data[anime_genre_column_name].apply(remove_out_brackets)\n",
    "anime_data[anime_genre_column_name]=anime_data[anime_genre_column_name].apply(remove_quote_mark)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Action,Adventure,Comedy,Drama,Sci-Fi,Space\n",
       "1                 Action,Space,Drama,Mystery,Sci-Fi\n",
       "2      Action,Sci-Fi,Adventure,Comedy,Drama,Shounen\n",
       "3    Action,Magic,Police,Supernatural,Drama,Mystery\n",
       "4            Adventure,Fantasy,Shounen,Supernatural\n",
       "Name: Genre, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_data[anime_genre_column_name].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = anime_data[anime_genre_column_name].unique()\n",
    "filtered_genres = set()\n",
    "for array in genres:\n",
    "    for genre in array.split(\",\"):\n",
    "        filtered_genres.add(genre.strip())\n",
    "\n",
    "# print(filtered_genres)\n",
    "for genre in filtered_genres:\n",
    "    with open(\"data/genres.txt\", \"a\") as file:\n",
    "        file.write(genre+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12193, 43)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 43 genres for 12193 animes.\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\",\"), binary='true')\n",
    "total_data = vectorizer.fit_transform(anime_data[anime_genre_column_name]).toarray()\n",
    "total_data.shape\n",
    "\n",
    "print(f\"We have a total of {total_data.shape[1]} genres for {total_data.shape[0]} animes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data # this is the label for our train data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train and valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is not needed as we are using the preprocessed synopsis\n",
    "\n",
    "# def format_synopsis(synopsis):\n",
    "#     \"\"\"Add spaces around punctuation and remove references to images/citations.\"\"\"\n",
    "\n",
    "#     # Add spaces behind punctuation\n",
    "#     synopsis = re.sub(r'(?<=[^\\s0-9])(?=[.,;?\"\\'>\\)\\]])', r' ', synopsis)\n",
    "\n",
    "#     # Add spaces before punctuation\n",
    "#     # 's will not be split from the word\n",
    "#     synopsis = re.sub(r'(?<=[.,;?\"\\'<\\)\\[])(?=[^\\ss])', r' ', synopsis)\n",
    "\n",
    "\n",
    "#     # Remove double spaces\n",
    "#     synopsis = re.sub(r'\\s\\s', r' ', synopsis)\n",
    "\n",
    "#     # Remove triple spaces\n",
    "#     synopsis = re.sub(r'\\s\\s\\s', r' ', synopsis)\n",
    "#     return synopsis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_anime_synopsis = []\n",
    "\n",
    "# # Iterate through all the original abstracts\n",
    "# for synopsis in original_anime_synopsis:\n",
    "#     # print(patent)\n",
    "#     formatted_anime_synopsis.append(format_synopsis(synopsis))\n",
    "\n",
    "# len(formatted_anime_synopsis)\n",
    "# print(formatted_anime_synopsis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# things to consider when encoding\n",
    "# https://wikidocs.net/44249\n",
    "\n",
    "lower = True  # Whether to set the text to lowercase.\n",
    "filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r'  # Characters to filter out of the text.\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(lower=lower, filters=filters)\n",
    "tokenizer.fit_on_texts(preprocessed_synopsis)\n",
    "test = tokenizer.texts_to_sequences(preprocessed_synopsis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See raw tokenized results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze tokenzied result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 40176\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 22383\n",
      "단어 집합에서 희귀 단어의 비율: 55.71236559139785\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.440063689293762\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to have word encodings for words that appeared only twice at most. We will ignore them in our tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max encoding integer: 40176\n"
     ]
    }
   ],
   "source": [
    "max_encoding_int = max([max(x) for x in test])\n",
    "print(f\"Max encoding integer: {max_encoding_int}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 17794\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict tokenzier to words that appear at least 3 times\n",
    "tokenizer = Tokenizer(num_words=vocab_size ,lower=lower, filters=filters)\n",
    "tokenizer.fit_on_texts(preprocessed_synopsis)\n",
    "tokenized_anime_synopsis = tokenizer.texts_to_sequences(preprocessed_synopsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max encoding integer: 17793\n"
     ]
    }
   ],
   "source": [
    "max_encoding_int = max([max(x) for x in tokenized_anime_synopsis])\n",
    "print(f\"Max encoding integer: {max_encoding_int}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our encoding integer is fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anime_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(tokenized_anime_synopsis) if len(sentence) < 1]\n",
    "print(drop_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synopsis count:  12193  genre count:  12193\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "print(\"synopsis count: \", len(tokenized_anime_synopsis), \" genre count: \" , len(total_data))\n",
    "features, labels = shuffle(tokenized_anime_synopsis, total_data, random_state=RANDOM_STATE)\n",
    "# Decide on number of samples for training\n",
    "# TRAIN_FRACTION is 0.7\n",
    "train_end = int(TRAIN_FRACTION * len(labels))\n",
    "train_features = features[:train_end]\n",
    "valid_features = features[train_end:]\n",
    "train_labels = labels[:train_end]\n",
    "print(train_labels)\n",
    "valid_labels = labels[train_end:]\n",
    "\n",
    "# Convert to arrays\n",
    "X_train, X_valid = train_features, valid_features\n",
    "y_train, y_valid = train_labels, valid_labels\n",
    "\n",
    "# X_train.shape\n",
    "# y_train.shape\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서로 다른 길이의 샘플들의 길이를 동일하게 맞춰주는 패딩 작업을 진행해보겠습니다. 전체 데이터에서 가장 길이가 긴 리뷰와 전체 데이터의 길이 분포를 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 236\n",
      "리뷰의 평균 길이 : 40.447334504979494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2.50e+02, 1.26e+03, 8.64e+02, 5.01e+02, 5.91e+02, 5.61e+02,\n",
       "        4.39e+02, 5.24e+02, 4.75e+02, 3.22e+02, 3.25e+02, 3.09e+02,\n",
       "        2.19e+02, 2.47e+02, 2.28e+02, 1.71e+02, 2.00e+02, 2.19e+02,\n",
       "        1.31e+02, 1.52e+02, 1.49e+02, 7.60e+01, 7.30e+01, 7.80e+01,\n",
       "        3.70e+01, 3.90e+01, 2.20e+01, 1.80e+01, 5.00e+00, 9.00e+00,\n",
       "        6.00e+00, 8.00e+00, 7.00e+00, 3.00e+00, 2.00e+00, 3.00e+00,\n",
       "        2.00e+00, 1.00e+00, 2.00e+00, 0.00e+00, 0.00e+00, 2.00e+00,\n",
       "        0.00e+00, 1.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 1.00e+00,\n",
       "        1.00e+00, 2.00e+00]),\n",
       " array([  2.  ,   6.68,  11.36,  16.04,  20.72,  25.4 ,  30.08,  34.76,\n",
       "         39.44,  44.12,  48.8 ,  53.48,  58.16,  62.84,  67.52,  72.2 ,\n",
       "         76.88,  81.56,  86.24,  90.92,  95.6 , 100.28, 104.96, 109.64,\n",
       "        114.32, 119.  , 123.68, 128.36, 133.04, 137.72, 142.4 , 147.08,\n",
       "        151.76, 156.44, 161.12, 165.8 , 170.48, 175.16, 179.84, 184.52,\n",
       "        189.2 , 193.88, 198.56, 203.24, 207.92, 212.6 , 217.28, 221.96,\n",
       "        226.64, 231.32, 236.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'length of samples')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of samples')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reference: https://wikidocs.net/44249\n",
    "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "avg = sum(map(len, X_train))/len(X_train)\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 90 이하인 샘플의 비율: 91.81019332161688\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def below_threshold_len(max_len, nexted_list):\n",
    "    count = 0\n",
    "    for s in nexted_list:\n",
    "        if(len(s) <= max_len):\n",
    "            count = count + 1\n",
    "    print(f\"전체 샘플 중 길이가 {max_len} 이하인 샘플의 비율: {(count / len(nexted_list))*100}\")\n",
    "\n",
    "max_len = math.floor(avg + 50)\n",
    "below_threshold_len(max_len, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7251, 92, 1808, 397, 51, 1124, 1127, 9392, 89, 12523, 148, 246, 6348, 12524, 6, 51, 162, 3712, 7251, 943, 181, 71, 1165, 651, 3712, 1038, 911, 4398, 14886, 1059, 121, 33, 4695, 71, 1680, 1802, 192, 3700, 28, 89, 10891, 5894, 6348, 2968, 1186, 2120, 5298, 14887, 419, 4695, 9668, 705, 7251, 1137, 162, 986, 561, 2248, 28, 744, 884, 85, 997, 2155, 797, 7251, 6, 21, 140, 2178, 567, 847, 1298, 567, 1, 9]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8535, 90), (3658, 90))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   567,     1,     9],\n",
       "       [    0,     0,     0, ...,     1,  1120,  1006],\n",
       "       [    0,     0,     0, ...,   717,  3970, 13737],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    28,     1,  3648],\n",
       "       [    0,     0,     0, ...,   137,  1936,  6924],\n",
       "       [    0,     0,     0, ...,   549,  1240,  6399]], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_valid = pad_sequences(X_valid, maxlen = max_len)\n",
    "X_train.shape, X_valid.shape\n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 101)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from keras.utils import get_file\n",
    "\n",
    "# Vectors to use\n",
    "# glove_vectors = './glove.6B.zip'\n",
    "\n",
    "# Download word embeddings if they are not present\n",
    "# if not os.path.exists(glove_vectors):\n",
    "#     glove_vectors = get_file('glove.6B.zip',\n",
    "#                              'http://nlp.stanford.edu/data/glove.6B.zip')\n",
    "#     os.system(f'unzip {glove_vectors}')\n",
    "\n",
    "# Load in unzipped file\n",
    "glove_vectors = '/Users/oztinman/rnn/synopsis_predictor/glove.6B/glove.6B.100d.txt'\n",
    "glove = np.loadtxt(glove_vectors, dtype='str', comments=None)\n",
    "glove.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to keep only those words that appear in our vocabulary. For words that are in our vocabulary but don't have an embedding, they will be represented as all 0s (a shortcoming that we can address by training our own embeddings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2080 words without pre-trained embeddings.\n"
     ]
    }
   ],
   "source": [
    "vectors = glove[:, 1:].astype('float')\n",
    "words = glove[:, 0]\n",
    "\n",
    "word_idx = dict(filter(lambda elem:elem[1] <= max_encoding_int, tokenizer.word_index.items()))\n",
    "idx_word = dict(filter(lambda elem:elem[0] <= max_encoding_int, tokenizer.index_word.items()))\n",
    "# idx_word = tokenizer.index_word\n",
    "num_words = vocab_size # This is the newly updated vocab_size\n",
    "\n",
    "# del glove\n",
    "word_lookup = {word: vector for word, vector in zip(words, vectors)}\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, vectors.shape[1]))\n",
    "\n",
    "not_found = 0\n",
    "\n",
    "for i, word in enumerate(word_idx.keys()):\n",
    "    # Look up the word embedding\n",
    "    vector = word_lookup.get(word, None)\n",
    "\n",
    "    # Record in matrix\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i + 1, :] = vector\n",
    "    else:\n",
    "        not_found += 1\n",
    "\n",
    "print(f'There were {not_found} words without pre-trained embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17794, 100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(query, embedding_matrix, word_idx, idx_word, n=10):\n",
    "    \"\"\"Find closest words to a query word in embeddings\"\"\"\n",
    "\n",
    "    idx = word_idx.get(query, None)\n",
    "    # Handle case where query is not in vocab\n",
    "    if idx is None:\n",
    "        print(f'{query} not found in vocab.')\n",
    "        return\n",
    "    else:\n",
    "        vec = embedding_matrix[idx]\n",
    "        # Handle case where word doesn't have an embedding\n",
    "        if np.all(vec == 0):\n",
    "            print(f'{query} has no pre-trained embedding.')\n",
    "            return\n",
    "        else:\n",
    "            # Calculate distance between vector and all others\n",
    "            dists = np.dot(embedding_matrix, vec)\n",
    "\n",
    "            # Sort indexes in reverse order\n",
    "            idxs = np.argsort(dists)[::-1][:n]\n",
    "            sorted_dists = dists[idxs]\n",
    "            closest = [idx_word[i] for i in idxs]\n",
    "\n",
    "    print(f'Query: {query}\\n')\n",
    "    max_len = max([len(i) for i in closest])\n",
    "    # Print out the word and cosine distances\n",
    "    for word, dist in zip(closest, sorted_dists):\n",
    "        print(f'Word: {word:15} Cosine Similarity: {round(dist, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: sword\n",
      "\n",
      "Word: sword           Cosine Similarity: 29.3167\n",
      "Word: swords          Cosine Similarity: 20.7288\n",
      "Word: dragon          Cosine Similarity: 19.6246\n",
      "Word: knife           Cosine Similarity: 17.9398\n",
      "Word: god             Cosine Similarity: 17.9074\n",
      "Word: blade           Cosine Similarity: 17.7469\n",
      "Word: spear           Cosine Similarity: 17.4721\n",
      "Word: dagger          Cosine Similarity: 16.5624\n",
      "Word: warrior         Cosine Similarity: 16.4934\n",
      "Word: sorcery         Cosine Similarity: 15.9276\n"
     ]
    }
   ],
   "source": [
    "find_closest('sword', embedding_matrix, word_idx, idx_word)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-79-0ae4c104c2fb>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-79-0ae4c104c2fb>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    Map words to an embedding\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def make_word_level_model(vocab_size,\n",
    "                          embedding_matrix,\n",
    "                          n_classes\n",
    "                          ):\n",
    "    \"\"\"Make a word level recurrent neural network with option for pretrained embeddings\n",
    "       and varying numbers of LSTM cell layers.\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    #Map words to an embedding\n",
    "    model.add(Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_matrix.shape[1],\n",
    "        weights=[embedding_matrix],   \n",
    "    ))\n",
    "\n",
    "    # model.add(Embedding(\n",
    "    #     vocab_size,\n",
    "    #     output_dim=50,\n",
    "    #     input_length=90,\n",
    "    # ))\n",
    "\n",
    "    # model.add(Embedding(\n",
    "    #     input_dim=num_words,\n",
    "    #     output_dim=embedding_matrix.shape[1],\n",
    "    #     weights=[embedding_matrix],   \n",
    "    # ))\n",
    "\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(LSTM(64))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # We have catgegories.\n",
    "    model.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 90, 50)            889700    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 90, 128)           91648     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 90, 128)           0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 43)                2795      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,033,551\n",
      "Trainable params: 1,033,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_word_level_model(\n",
    "    vocab_size,\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    n_classes=labels.shape[1],\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"anime_plot_genre_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_callbacks(model_name, save=SAVE_MODEL):\n",
    "    \"\"\"Make list of callbacks for training\"\"\"\n",
    "    # callbacks = [EarlyStopping(monitor='val_loss', patience=5)]\n",
    "    callbacks = []\n",
    "\n",
    "    if save:\n",
    "        callbacks.append(\n",
    "            ModelCheckpoint(\n",
    "                f'{model_name}.h5',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False))\n",
    "    return callbacks\n",
    "\n",
    "callbacks = make_callbacks(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8535, 90)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8535, 43)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3658, 90)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3658, 43)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape\n",
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "267/267 [==============================] - 40s 150ms/step - loss: 0.1304 - accuracy: 0.4664 - val_loss: 0.2064 - val_accuracy: 0.3114\n",
      "Epoch 2/50\n",
      "267/267 [==============================] - 45s 168ms/step - loss: 0.1278 - accuracy: 0.4715 - val_loss: 0.2093 - val_accuracy: 0.3106\n",
      "Epoch 3/50\n",
      "267/267 [==============================] - 46s 171ms/step - loss: 0.1246 - accuracy: 0.4728 - val_loss: 0.2103 - val_accuracy: 0.3048\n",
      "Epoch 4/50\n",
      "267/267 [==============================] - 41s 153ms/step - loss: 0.1218 - accuracy: 0.4737 - val_loss: 0.2127 - val_accuracy: 0.3037\n",
      "Epoch 5/50\n",
      "267/267 [==============================] - 42s 158ms/step - loss: 0.1193 - accuracy: 0.4821 - val_loss: 0.2157 - val_accuracy: 0.3209\n",
      "Epoch 6/50\n",
      "267/267 [==============================] - 45s 168ms/step - loss: 0.1166 - accuracy: 0.4889 - val_loss: 0.2164 - val_accuracy: 0.3048\n",
      "Epoch 7/50\n",
      "267/267 [==============================] - 42s 157ms/step - loss: 0.1141 - accuracy: 0.4921 - val_loss: 0.2157 - val_accuracy: 0.3275\n",
      "Epoch 8/50\n",
      "267/267 [==============================] - 44s 166ms/step - loss: 0.1108 - accuracy: 0.5032 - val_loss: 0.2204 - val_accuracy: 0.3032\n",
      "Epoch 9/50\n",
      "267/267 [==============================] - 43s 162ms/step - loss: 0.1085 - accuracy: 0.4990 - val_loss: 0.2224 - val_accuracy: 0.3242\n",
      "Epoch 10/50\n",
      "267/267 [==============================] - 41s 155ms/step - loss: 0.1058 - accuracy: 0.5070 - val_loss: 0.2259 - val_accuracy: 0.3103\n",
      "Epoch 11/50\n",
      "267/267 [==============================] - 42s 156ms/step - loss: 0.1032 - accuracy: 0.5079 - val_loss: 0.2330 - val_accuracy: 0.3149\n",
      "Epoch 12/50\n",
      "267/267 [==============================] - 42s 159ms/step - loss: 0.1010 - accuracy: 0.5183 - val_loss: 0.2304 - val_accuracy: 0.3308\n",
      "Epoch 13/50\n",
      "267/267 [==============================] - 46s 172ms/step - loss: 0.0986 - accuracy: 0.5299 - val_loss: 0.2326 - val_accuracy: 0.3114\n",
      "Epoch 14/50\n",
      "267/267 [==============================] - 45s 168ms/step - loss: 0.0963 - accuracy: 0.5349 - val_loss: 0.2360 - val_accuracy: 0.3045\n",
      "Epoch 15/50\n",
      "267/267 [==============================] - 42s 157ms/step - loss: 0.0939 - accuracy: 0.5338 - val_loss: 0.2465 - val_accuracy: 0.3059\n",
      "Epoch 16/50\n",
      "267/267 [==============================] - 45s 168ms/step - loss: 0.0921 - accuracy: 0.5435 - val_loss: 0.2446 - val_accuracy: 0.3212\n",
      "Epoch 17/50\n",
      "267/267 [==============================] - 45s 167ms/step - loss: 0.0905 - accuracy: 0.5488 - val_loss: 0.2486 - val_accuracy: 0.2985\n",
      "Epoch 18/50\n",
      "267/267 [==============================] - 47s 176ms/step - loss: 0.0884 - accuracy: 0.5426 - val_loss: 0.2517 - val_accuracy: 0.3125\n",
      "Epoch 19/50\n",
      "267/267 [==============================] - 39s 147ms/step - loss: 0.0862 - accuracy: 0.5524 - val_loss: 0.2558 - val_accuracy: 0.3125\n",
      "Epoch 20/50\n",
      "267/267 [==============================] - 46s 172ms/step - loss: 0.0848 - accuracy: 0.5624 - val_loss: 0.2626 - val_accuracy: 0.3089\n",
      "Epoch 21/50\n",
      "267/267 [==============================] - 44s 164ms/step - loss: 0.0824 - accuracy: 0.5598 - val_loss: 0.2662 - val_accuracy: 0.3034\n",
      "Epoch 22/50\n",
      "267/267 [==============================] - 42s 159ms/step - loss: 0.0810 - accuracy: 0.5665 - val_loss: 0.2672 - val_accuracy: 0.3125\n",
      "Epoch 23/50\n",
      "267/267 [==============================] - 44s 164ms/step - loss: 0.0796 - accuracy: 0.5721 - val_loss: 0.2762 - val_accuracy: 0.3138\n",
      "Epoch 24/50\n",
      "267/267 [==============================] - 40s 151ms/step - loss: 0.0783 - accuracy: 0.5756 - val_loss: 0.2834 - val_accuracy: 0.3185\n",
      "Epoch 25/50\n",
      "267/267 [==============================] - 42s 159ms/step - loss: 0.0774 - accuracy: 0.5701 - val_loss: 0.2790 - val_accuracy: 0.3245\n",
      "Epoch 26/50\n",
      "267/267 [==============================] - 43s 160ms/step - loss: 0.0753 - accuracy: 0.5809 - val_loss: 0.2832 - val_accuracy: 0.3207\n",
      "Epoch 27/50\n",
      "267/267 [==============================] - 41s 154ms/step - loss: 0.0736 - accuracy: 0.5780 - val_loss: 0.2861 - val_accuracy: 0.3248\n",
      "Epoch 28/50\n",
      "267/267 [==============================] - 45s 168ms/step - loss: 0.0724 - accuracy: 0.5904 - val_loss: 0.2927 - val_accuracy: 0.3018\n",
      "Epoch 29/50\n",
      "267/267 [==============================] - 42s 159ms/step - loss: 0.0711 - accuracy: 0.5877 - val_loss: 0.2916 - val_accuracy: 0.3261\n",
      "Epoch 30/50\n",
      "267/267 [==============================] - 43s 162ms/step - loss: 0.0697 - accuracy: 0.5913 - val_loss: 0.3017 - val_accuracy: 0.3215\n",
      "Epoch 31/50\n",
      "267/267 [==============================] - 44s 166ms/step - loss: 0.0687 - accuracy: 0.5917 - val_loss: 0.3025 - val_accuracy: 0.3188\n",
      "Epoch 32/50\n",
      "267/267 [==============================] - 43s 163ms/step - loss: 0.0674 - accuracy: 0.6005 - val_loss: 0.3065 - val_accuracy: 0.3256\n",
      "Epoch 33/50\n",
      "267/267 [==============================] - 44s 166ms/step - loss: 0.0666 - accuracy: 0.5937 - val_loss: 0.3066 - val_accuracy: 0.3188\n",
      "Epoch 34/50\n",
      "267/267 [==============================] - 50s 187ms/step - loss: 0.0657 - accuracy: 0.5906 - val_loss: 0.3160 - val_accuracy: 0.3193\n",
      "Epoch 35/50\n",
      "267/267 [==============================] - 49s 184ms/step - loss: 0.0646 - accuracy: 0.6030 - val_loss: 0.3268 - val_accuracy: 0.3204\n",
      "Epoch 36/50\n",
      "267/267 [==============================] - 45s 167ms/step - loss: 0.0627 - accuracy: 0.6070 - val_loss: 0.3279 - val_accuracy: 0.3305\n",
      "Epoch 37/50\n",
      "267/267 [==============================] - 50s 186ms/step - loss: 0.0619 - accuracy: 0.6012 - val_loss: 0.3275 - val_accuracy: 0.3248\n",
      "Epoch 38/50\n",
      "267/267 [==============================] - 45s 167ms/step - loss: 0.0609 - accuracy: 0.6059 - val_loss: 0.3373 - val_accuracy: 0.3144\n",
      "Epoch 39/50\n",
      "267/267 [==============================] - 47s 175ms/step - loss: 0.0598 - accuracy: 0.6115 - val_loss: 0.3387 - val_accuracy: 0.3226\n",
      "Epoch 40/50\n",
      "267/267 [==============================] - 46s 171ms/step - loss: 0.0592 - accuracy: 0.6207 - val_loss: 0.3481 - val_accuracy: 0.3330\n",
      "Epoch 41/50\n",
      "267/267 [==============================] - 47s 177ms/step - loss: 0.0582 - accuracy: 0.6141 - val_loss: 0.3465 - val_accuracy: 0.3332\n",
      "Epoch 42/50\n",
      "267/267 [==============================] - 42s 157ms/step - loss: 0.0577 - accuracy: 0.6183 - val_loss: 0.3595 - val_accuracy: 0.3190\n",
      "Epoch 43/50\n",
      "267/267 [==============================] - 45s 167ms/step - loss: 0.0568 - accuracy: 0.6166 - val_loss: 0.3515 - val_accuracy: 0.3283\n",
      "Epoch 44/50\n",
      "267/267 [==============================] - 50s 189ms/step - loss: 0.0553 - accuracy: 0.6200 - val_loss: 0.3683 - val_accuracy: 0.3272\n",
      "Epoch 45/50\n",
      "267/267 [==============================] - 48s 180ms/step - loss: 0.0541 - accuracy: 0.6281 - val_loss: 0.3717 - val_accuracy: 0.3256\n",
      "Epoch 46/50\n",
      "267/267 [==============================] - 51s 191ms/step - loss: 0.0545 - accuracy: 0.6164 - val_loss: 0.3639 - val_accuracy: 0.3352\n",
      "Epoch 47/50\n",
      "267/267 [==============================] - 48s 179ms/step - loss: 0.0528 - accuracy: 0.6196 - val_loss: 0.3812 - val_accuracy: 0.3237\n",
      "Epoch 48/50\n",
      "267/267 [==============================] - 46s 173ms/step - loss: 0.0528 - accuracy: 0.6165 - val_loss: 0.3668 - val_accuracy: 0.3286\n",
      "Epoch 49/50\n",
      "267/267 [==============================] - 50s 186ms/step - loss: 0.0518 - accuracy: 0.6129 - val_loss: 0.3796 - val_accuracy: 0.3447\n",
      "Epoch 50/50\n",
      "267/267 [==============================] - 48s 180ms/step - loss: 0.0508 - accuracy: 0.6212 - val_loss: 0.3843 - val_accuracy: 0.3245\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_name + \".h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_predict = \"The story starts with a young man in a dream world full of elves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'adventure',\n",
       " 'cars',\n",
       " 'comedy',\n",
       " 'dementia',\n",
       " 'demons',\n",
       " 'drama',\n",
       " 'ecchi',\n",
       " 'fantasy',\n",
       " 'game',\n",
       " 'harem',\n",
       " 'hentai',\n",
       " 'historical',\n",
       " 'horror',\n",
       " 'josei',\n",
       " 'kids',\n",
       " 'magic',\n",
       " 'martial arts',\n",
       " 'mecha',\n",
       " 'military',\n",
       " 'music',\n",
       " 'mystery',\n",
       " 'parody',\n",
       " 'police',\n",
       " 'psychological',\n",
       " 'romance',\n",
       " 'samurai',\n",
       " 'school',\n",
       " 'sci-fi',\n",
       " 'seinen',\n",
       " 'shoujo',\n",
       " 'shoujo ai',\n",
       " 'shounen',\n",
       " 'shounen ai',\n",
       " 'slice of life',\n",
       " 'space',\n",
       " 'sports',\n",
       " 'super power',\n",
       " 'supernatural',\n",
       " 'thriller',\n",
       " 'vampire',\n",
       " 'yaoi',\n",
       " 'yuri']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(string_to_predict):\n",
    "    \"\"\"Predict the genre of a string\"\"\"\n",
    "\n",
    "    # Clean input string\n",
    "    string_to_predict = preprocess_phrase(string_to_predict)\n",
    "\n",
    "    # Encode string\n",
    "    encoded = tokenizer.texts_to_sequences([string_to_predict])\n",
    "\n",
    "    # Pad sequence\n",
    "    padded = pad_sequences(encoded, maxlen=X_train.shape[1])\n",
    "\n",
    "    # Make prediction\n",
    "    pred = model.predict(padded)\n",
    "\n",
    "\n",
    "    # Get index corresponding to the highest probability\n",
    "\n",
    "    # Get top 3 predictions\n",
    "    top_3 = pred.argsort()[0][-3:]\n",
    "    print(top_3)\n",
    "    # Get genres corresponding to those predictions\n",
    "    for genre in top_3:\n",
    "        print(vectorizer.get_feature_names()[genre])\n",
    "    \n",
    "\n",
    "    # Return predicted genre and probability\n",
    "    # return idx2genre[max_prob], pred[0, max_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[12  8 11]\n",
      "historical\n",
      "fantasy\n",
      "hentai\n"
     ]
    }
   ],
   "source": [
    "predict_genre(string_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 40ms/step\n",
      "[27 34 20]\n",
      "school\n",
      "slice of life\n",
      "music\n"
     ]
    }
   ],
   "source": [
    "predict_genre(\"A girl comes to a shop to buy some food. Then a handsome boy appears\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "[19 22 11]\n",
      "military\n",
      "parody\n",
      "hentai\n"
     ]
    }
   ],
   "source": [
    "predict_genre(\"A spy comes in to the store and steals a dagger from a woman. The woman is desparate to find the lost treasuer and searches out to find the criminal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[ 1 15  8]\n",
      "adventure\n",
      "kids\n",
      "fantasy\n"
     ]
    }
   ],
   "source": [
    "predict_genre(\"A young boy starts his journey to become the best pokemon trainer in the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[26 15 12]\n",
      "samurai\n",
      "kids\n",
      "historical\n"
     ]
    }
   ],
   "source": [
    "predict_genre(\"A dog loses its owner and goes on a journey to find him\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "[ 0  6 12]\n",
      "action\n",
      "drama\n",
      "historical\n"
     ]
    }
   ],
   "source": [
    "predict_genre(\"Spies are sent to a mission to find the lost treasure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[30 25  6]\n",
      "shoujo\n",
      "romance\n",
      "drama\n"
     ]
    }
   ],
   "source": [
    "predict_genre(\"Tentacles come out of the sky and start attacking people. A group of friends try to save the world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One Piece'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'Gol D. Roger was known as the \"Pirate King,\" the strongest and most infamous being to have sailed the Grand Line. The capture and execution of Roger by the World Government brought a change throughout the world. His last words before his death revealed the existence of the greatest treasure in the world, One Piece. It was this revelation that brought about the Grand Age of Pirates, men who dreamed of finding One Piece—which promises an unlimited amount of riches and fame—and quite possibly the pinnacle of glory and the title of the Pirate King. \\r\\n \\r\\nEnter Monkey D. Luffy, a 17-year-old boy who defies your standard definition of a pirate. Rather than the popular persona of a wicked, hardened, toothless pirate ransacking villages for fun, Luffy’s reason for being a pirate is one of pure wonder: the thought of an exciting adventure that leads him to intriguing people and ultimately, the promised treasure. Following in the footsteps of his childhood hero, Luffy and his crew travel across the Grand Line, experiencing crazy adventures, unveiling dark mysteries and battling strong enemies, all in order to reach the most coveted of all fortunes—One Piece. \\r\\n \\r\\n[Written by MAL Rewrite] '"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "[32  0  3]\n",
      "shounen\n",
      "action\n",
      "comedy\n"
     ]
    }
   ],
   "source": [
    "index = 11\n",
    "anime_data.Title[index]\n",
    "anime_data[anime_synopsis_column_name][index]\n",
    "predict_genre(anime_data[anime_synopsis_column_name][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
